{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [프로젝트]얼굴합성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목표\n",
    "\n",
    "* 얼굴을 인식하고 랜드마크를 표시하고 각 값을 읽어들인다.\n",
    "* 특정 부위를 추출하고 대상에 자연스럽게 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 기술\n",
    "\n",
    "* 얼굴 인식하는 기술\n",
    "* 랜드마크 표시하는 기술\n",
    "* 자연스럽게 합쳐지는 기술"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 준비사항\n",
    "\n",
    "* 필요한 라이브러리를 설치한다.\n",
    "\n",
    "    - pip install imutils\n",
    "    - pip install face_utils\n",
    "    - pip install dlib\n",
    "    \n",
    "* 랜드마크에 필요한 데이터를 다운로드 받는다.\n",
    "\n",
    "    - http://dlib.net/files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 로딩한다. cv2, numpy, \n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import face_utils, resize\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils, resize\n",
    "import numpy as np\n",
    "\n",
    "orange_img = cv2.imread('data/orange.jpg')\n",
    "orange_img = cv2.resize(orange_img, dsize=(512, 512))\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('data/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(\"data/girl.mp4\")\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    faces = detector(img)\n",
    "\n",
    "    result = orange_img.copy()\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        \n",
    "        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "        face_img = img[y1:y2, x1:x2].copy()\n",
    "\n",
    "        shape = predictor(img, face)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # for p in shape:\n",
    "        #     cv2.circle(face_img, center=(p[0] - x1, p[1] - y1), radius=2, color=255, thickness=-1)\n",
    "\n",
    "        # eyes\n",
    "        le_x1 = shape[36, 0]\n",
    "        le_y1 = shape[37, 1]\n",
    "        le_x2 = shape[39, 0]\n",
    "        le_y2 = shape[41, 1]\n",
    "        le_margin = int((le_x2 - le_x1) * 0.18)\n",
    "\n",
    "        re_x1 = shape[42, 0]\n",
    "        re_y1 = shape[43, 1]\n",
    "        re_x2 = shape[45, 0]\n",
    "        re_y2 = shape[47, 1]\n",
    "        re_margin = int((re_x2 - re_x1) * 0.18)\n",
    "\n",
    "        left_eye_img = img[le_y1-le_margin:le_y2+le_margin, le_x1-le_margin:le_x2+le_margin].copy()\n",
    "        right_eye_img = img[re_y1-re_margin:re_y2+re_margin, re_x1-re_margin:re_x2+re_margin].copy()\n",
    "\n",
    "        left_eye_img = resize(left_eye_img, width=100)\n",
    "        right_eye_img = resize(right_eye_img, width=100)\n",
    "\n",
    "        result = cv2.seamlessClone(\n",
    "            left_eye_img,\n",
    "            result,\n",
    "            np.full(left_eye_img.shape[:2], 255, left_eye_img.dtype),\n",
    "            (100, 200),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        result = cv2.seamlessClone(\n",
    "            right_eye_img,\n",
    "            result,\n",
    "            np.full(right_eye_img.shape[:2], 255, right_eye_img.dtype),\n",
    "            (250, 200),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        # mouth\n",
    "        mouth_x1 = shape[48, 0]\n",
    "        mouth_y1 = shape[50, 1]\n",
    "        mouth_x2 = shape[54, 0]\n",
    "        mouth_y2 = shape[57, 1]\n",
    "        mouth_margin = int((mouth_x2 - mouth_x1) * 0.1)\n",
    "\n",
    "        mouth_img = img[mouth_y1-mouth_margin:mouth_y2+mouth_margin, mouth_x1-mouth_margin:mouth_x2+mouth_margin].copy()\n",
    "\n",
    "        mouth_img = resize(mouth_img, width=250)\n",
    "\n",
    "        result = cv2.seamlessClone(\n",
    "            mouth_img,\n",
    "            result,\n",
    "            np.full(mouth_img.shape[:2], 255, mouth_img.dtype),\n",
    "            (180, 320),\n",
    "            cv2.MIXED_CLONE\n",
    "        )\n",
    "\n",
    "        # cv2.imshow('left', left_eye_img)\n",
    "        # cv2.imshow('right', right_eye_img)\n",
    "        # cv2.imshow('mouth', mouth_img)\n",
    "        # cv2.imshow('face', face_img)\n",
    "\n",
    "        cv2.imshow('result', result)\n",
    "\n",
    "    # cv2.imshow('img', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
